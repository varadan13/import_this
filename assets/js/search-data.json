{
  
    
        "post0": {
            "title": "Interpretation of Partial regression coefficients.",
            "content": "# import pandas as pd # import numpy as np # import statsmodels.api as sm # import tabulate as tb # Copy the code of udregression from the link # provided below and run it in your environment. . Let $X_1$ be an explanatory variable. Let&#39;s suppose $X_1$ ~ $exp( lambda = 1)$ Let&#39;s use numpy and draw 15 random observation from the above distribution and assign the variable X1 to it. . X1 = np.random.exponential(size=15) . Let $X_2$ like $X_1$ be another explanatory variable which follows exponential distribution with mean = 1. Let&#39;s use numpy to create random vector X2 of size 15 from the required distribution . X2 = np.random.exponential(size=15) . We know that the error is assumed to follow the standard normal distribution so let&#39;s use numpy to generate a random error vector of size 15 from the standard normal distribtuion . error=np.random.normal(size=15) # by default numpy&#39;s normal function # outputs standard normal variates . Let Y be a dependent variable that is generated from X1,X2 and error. Let&#39;s suppose Y is generated as follows: $Y=1.11+123X_1+45X_2+error$ Therefore the linear model we are considering is $Y= beta_0+ beta_1X_1+ beta_2X_2+error$ with $ beta_0=1.11, beta_1=123, beta_2=45$ Let&#39;s interpret beta1 and beta2 . Y=1.11+123*X1+45*X2+error . To interpret $ beta_1$. First, Let&#39;s regress Y with $X_2$ . reg =udregression(X2,Y).fit_model() # don&#39;t worry about udregression # it is a custom class I wrote # and for the code click the below link. . Link to udregreesison&#39;s source code . Let&#39;s now find the residuals of this regression . residual= Y -reg.fittedvalues residual . array([ -9.91016593, -94.00822722, -5.7247282 , 65.59993044, 42.23952437, 14.23110086, 36.70187822, -82.68784607, -67.94269339, -105.34239585, -17.82715355, 4.53419721, -106.44550192, 38.80625987, 287.77582115]) . Let&#39;s now regress the residuals with X1 and inspect the obtained parameter . reg =udregression(X1,residual).fit_model() slope = reg.params[1] slope . 122.63790390315614 . We can see that the slope is closer to $ beta_1$ and if the observation is large we can check that it will be equal to $ beta_1$. Notice that we obtained $ beta_1$ as slope coefficient while regressing X1 with the residual of the regression of X2 and Y. . Here Residuals act as a measure of the variance of Y that has not been captured by X2. . Regression(residual,$X_1$) is attempting to explain the variance of Y that has not been explained by $X_2$. . From single variable regression the slope parameter has the following interpretation: slope parameter measures the change in Y or dependent variable due to an unit change in the independent variable. . Therefore, $ beta_1$ measures the change in residual due to an unit change in $X_1$. Let&#39;s apply the definition of residual on the preceding sentence and rewrite it. $ beta_1$ measures the change in Y from an unit change in $X_1$ after removing the influence of $X_2$ on Y. . Let&#39;s define $ beta_2$ using $ beta_1$&#39;s definition as a template. . $ beta_2$ measures the change in Y from an unit change in $X_2$ after removing the influence of $X_1$ on Y. . Let&#39;s check if it is indeed true. . To interpret $ beta_2$ . regressing Y with $X_1$ . reg =udregression(X1,Y).fit_model() . finding the residual . residual = Y - reg.fittedvalues . regressing residual with X2 and finding the slope . reg =udregression(X2,residual).fit_model() slope=reg.params[1] slope . 45.28046614638129 . We can see that the slope is indeed equal to $ beta_2$ . These interpretations are however valid as long as the underlying assumptions are approximately valid . For example let&#39;s do the following . X2=0.99*X1 Y=1.11+123*X1+45*X2+error # we have created a strongly correlated X1 and X2 . reg =udregression(X1,Y).fit_model() residue = Y - reg.fittedvalues reg =udregression(X2,residue).fit_model() slope=reg.params[1] slope . 1.6479439340910673e-14 . We can see that the above slope not equal to $ beta_2$ and therefore we cannot use the interpretation of $ beta_2$ we have learnt here. . Conclusion . $ beta_1$ measures the change in Y from an unit change in $X_1$ after removing the influence of $X_2$ on Y. | $ beta_2$ measures the change in Y from an unit change in $X_2$ after removing the influence of $X_1$ on Y. | .",
            "url": "https://varadan13.github.io/import_this/linear%20algebra%20tutorial/2021/04/17/intprtPRC.html",
            "relUrl": "/linear%20algebra%20tutorial/2021/04/17/intprtPRC.html",
            "date": " • Apr 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Dummy Variable Regression",
            "content": "import pandas as pd import numpy as np # Load the data csv=&#39;https://raw.githubusercontent.com/varadan13/Data_Bank/main/Econ%20data/dummy_reg_gujar.csv&#39; data = pd.read_csv(csv).drop([&#39;Unnamed: 4&#39;,&#39;Spending&#39;],axis=1) . data.head(5) . Salary D2 D3 . 0 19583.0 | 1 | 0 | . 1 20263.0 | 1 | 0 | . 2 20325.0 | 1 | 0 | . 3 26800.0 | 1 | 0 | . 4 29470.0 | 1 | 0 | . The Data has information on average salary (in dollars) of public school teachers in 50 states and the District of Columbia for the year 1985. These 51 areas are classified into three geographical regions: (1) Northeast and North Central (21 states in all), (2) South (17 states in all), and (3) West (13 states in all). . $D_2$ and $D_3$ are dummy variables where $D_2 = 1$ when the area is northeast and northcentral and 0 otherwise $D_3 = 1$ when the area is south and 0 otherwise When both $D_2$ &amp; $D_3$ equal to 0 then the area is west. . Let&#39;s compute the avg average salary by the area. . North_Avg = data.loc[data[&#39;D2&#39;]==1].Salary.mean() np.round(North_Avg,2) # = mean average salary in the northern region . 24424.14 . South_Avg = data.loc[data[&#39;D3&#39;]==1].Salary.mean() South_Avg # = mean average salary in the southern region . 22894.0 . West_Avg = data.loc[(data[&#39;D3&#39;]==0) &amp; (data[&#39;D2&#39;]==0)].Salary.mean() np.round(West_Avg,2) # = mean average salary in the western region . 26158.62 . We can see that they are different but are they statistically different? . We can obviously use ANOVA but let&#39;s use Regression to find the answer . The model we are going to fit here is as follows: . $avgSalary = beta_0+ beta_1D_2+ beta_2D_3$ . Let&#39;s intrepret the betas . $E(avgSalary|D_2=0,D_3=0)= beta_0$ . $E(avgSalary|D_2=1,D_3=0)= beta_1$ . $E(avgSalary|D_2=0,D_3=1)= beta_2$ . beta0 is the mean of avgSalary in west and likewise for the slope parameters. . Let&#39;s fit the model and find out if there are any statistical significance . X=data.drop([&#39;Salary&#39;],axis=1).to_numpy() Y=data.Salary.to_numpy() reg=udregression(X,Y) . reg.print_result() # x1 represents D2 and x2 is D3 . var coef st error t values p values LL RL -- -- - - - -- const 26158.6 1128.52 23.1795 1.0227e-27 23889.6 28427.7 x1 -1734.47 1435.95 -1.20789 0.233007 -4621.65 1152.7 x2 -3264.62 1499.15 -2.17764 0.0343794 -6278.87 -250.363 rsquared rsquared_Adj fvalue - -- -- 0.0900828 0.0521696 2.37603 . We can see that the p value for D2 is not significant. What does that mean? . It means that the mean value of avg salary of north and northeastern region is equal to the mean value of west . Since we have a significant p value for D3 it means that mean avg salary of south is different from the west. . What exactly are the values of avg salary from this model? . avg_west=avg_north=reg.fit_model().params[0] # mean average salary in western # and northern region derived from # the model avg_south=reg.fit_model().params[0]+reg.fit_model().params[2] # mean average # salary in south # derived from # the model . print(&quot;average salary in the west = &quot;, np.round(avg_west,2)) print(&quot;average salary in the north = &quot;, np.round(avg_north,2)) print(&quot;average salary in the south = &quot;, avg_south) . average salary in the west = 26158.62 average salary in the north = 26158.62 average salary in the south = 22894.0 . Let&#39;s do an Anova here. . from statsmodels.formula.api import ols def create_treatments_col(DataFrame): if DataFrame.D2==1 and DataFrame.D3==0: return &#39;NORTH&#39; elif DataFrame.D2==0 and DataFrame.D3==1: return &#39;SOUTH&#39; else: return &#39;WEST&#39; data[&#39;treatments&#39;]=data.apply(create_treatments_col,axis=1) data_ANOVA=data.drop([&#39;D2&#39;,&#39;D3&#39;],axis=1) . data_ANOVA.head(5) . Salary treatments . 0 19583.0 | NORTH | . 1 20263.0 | NORTH | . 2 20325.0 | NORTH | . 3 26800.0 | NORTH | . 4 29470.0 | NORTH | . model = ols(&#39;Salary ~ C(treatments)&#39;, data=data_ANOVA).fit() anova_table = sm.stats.anova_lm(model, typ=2) anova_table . sum_sq df F PR(&gt;F) . C(treatments) 7.867655e+07 | 2.0 | 2.376027 | 0.103764 | . Residual 7.947037e+08 | 48.0 | NaN | NaN | . from scipy.stats import f pvalue=1-f.cdf(2.376027,2,48) pvalue&lt;0.05 # = hence insignificant result # can&#39;t tell why this happened? . False . udregression codes . import statsmodels.api as sm import tabulate as tb # to draw tables class udregression(object): &quot;&quot;&quot;udregression stands for a class that is user defined to do regression&quot;&quot;&quot; def __init__(self,X,Y,intercept=True): self.X=X self.Y=Y self.intercept=intercept def fit_model(self): if self.intercept==True: X1=np.column_stack([[1 for _ in range(self.X.shape[0])],self.X]) model=sm.OLS(self.Y,X1) f_model=model.fit() else: model=sm.OLS(self.Y,self.X) f_model=model.fit() return f_model def print_result(self): fitted_model=self.fit_model() length=len(fitted_model.summary().tables[1].data) var=[i[0] for i in fitted_model.summary().tables[1].data[1:length]] prtmp1={&#39;var&#39;:var,&#39;coef&#39;:fitted_model.params, &#39;st error&#39;:fitted_model.bse,&#39;t values&#39;:fitted_model.tvalues, &#39;p values&#39;:fitted_model.pvalues,&#39;LL&#39;:fitted_model.conf_int()[:,0], &#39;RL&#39;:fitted_model.conf_int()[:,1]} prtmp2={&#39;rsquared&#39;:[fitted_model.rsquared], &#39;rsquared_Adj&#39;:[fitted_model.rsquared_adj], &#39;fvalue&#39;:[fitted_model.fvalue]} print(tb.tabulate(prtmp1,headers=&quot;keys&quot;)) print() print(tb.tabulate(prtmp2,headers=&quot;keys&quot;)) def __repr__(self): return &quot;a custom regression runner has been intialised&quot; .",
            "url": "https://varadan13.github.io/import_this/linear%20algebra%20tutorial/2021/04/16/dummy-var.html",
            "relUrl": "/linear%20algebra%20tutorial/2021/04/16/dummy-var.html",
            "date": " • Apr 16, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "LIST, TUPLES AND NAMED TUPLES",
            "content": "Build a list of unicode codepoints from a string. . symbols = &#39;$%@*&#39; codes=[] for symbol in symbols: codes.append(ord(symbol)) codes . [36, 37, 64, 42] . Build a list of unicode codepoints from a string using list comp . [ord(symbol) for symbol in symbols] . [36, 37, 64, 42] . print([x for x in range(10)]) x # list comp does not leak any internally defined variables . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . NameError Traceback (most recent call last) &lt;ipython-input-3-39d6ba7356ef&gt; in &lt;module&gt;() 1 print([x for x in range(10)]) -&gt; 2 x # list comp does not leak any internally defined variables NameError: name &#39;x&#39; is not defined . Build cartesian products first using only for loop then using list comp . chars = [&#39;Harry Potter&#39;,&#39;John Hammond&#39;,&#39;Tony Montana&#39;] movies = [&#39;Goblet of fire&#39;,&#39;Jurassic Park&#39;,&#39;scarface&#39;] l=[] for char in chars: for movie in movies: l.append((char,movie)) print(l) . [(&#39;Harry Potter&#39;, &#39;Goblet of fire&#39;), (&#39;Harry Potter&#39;, &#39;Jurassic Park&#39;), (&#39;Harry Potter&#39;, &#39;scarface&#39;), (&#39;John Hammond&#39;, &#39;Goblet of fire&#39;), (&#39;John Hammond&#39;, &#39;Jurassic Park&#39;), (&#39;John Hammond&#39;, &#39;scarface&#39;), (&#39;Tony Montana&#39;, &#39;Goblet of fire&#39;), (&#39;Tony Montana&#39;, &#39;Jurassic Park&#39;), (&#39;Tony Montana&#39;, &#39;scarface&#39;)] . [(char,movie) for char in chars for movie in movies] . [(&#39;Harry Potter&#39;, &#39;Goblet of fire&#39;), (&#39;Harry Potter&#39;, &#39;Jurassic Park&#39;), (&#39;Harry Potter&#39;, &#39;scarface&#39;), (&#39;John Hammond&#39;, &#39;Goblet of fire&#39;), (&#39;John Hammond&#39;, &#39;Jurassic Park&#39;), (&#39;John Hammond&#39;, &#39;scarface&#39;), (&#39;Tony Montana&#39;, &#39;Goblet of fire&#39;), (&#39;Tony Montana&#39;, &#39;Jurassic Park&#39;), (&#39;Tony Montana&#39;, &#39;scarface&#39;)] . [(movie,char) for char in chars for movie in movies] . [(&#39;Goblet of fire&#39;, &#39;Harry Potter&#39;), (&#39;Jurassic Park&#39;, &#39;Harry Potter&#39;), (&#39;scarface&#39;, &#39;Harry Potter&#39;), (&#39;Goblet of fire&#39;, &#39;John Hammond&#39;), (&#39;Jurassic Park&#39;, &#39;John Hammond&#39;), (&#39;scarface&#39;, &#39;John Hammond&#39;), (&#39;Goblet of fire&#39;, &#39;Tony Montana&#39;), (&#39;Jurassic Park&#39;, &#39;Tony Montana&#39;), (&#39;scarface&#39;, &#39;Tony Montana&#39;)] . Various ways to unpack a tuple . A,B,*C=range(10) print(&#39;A= &#39;,A) print(&#39;B= &#39;,B) print(&#39;C= &#39;,C) . A= 0 B= 1 C= [2, 3, 4, 5, 6, 7, 8, 9] . A,*B,C=range(10) print(&#39;A= &#39;,A) print(&#39;B= &#39;,B) print(&#39;C= &#39;,C) . A= 0 B= [1, 2, 3, 4, 5, 6, 7, 8] C= 9 . *A,B,C=range(10) print(&#39;A= &#39;,A) print(&#39;B= &#39;,B) print(&#39;C= &#39;,C) . A= [0, 1, 2, 3, 4, 5, 6, 7] B= 8 C= 9 . *A,_,C=range(10) print(&#39;A= &#39;,A) #print(&#39;B= &#39;,B) print(&#39;C= &#39;,C) . A= [0, 1, 2, 3, 4, 5, 6, 7] C= 9 . A,_,C=range(10) print(&#39;A= &#39;,A) #print(&#39;B= &#39;,B) print(&#39;C= &#39;,C) . ValueError Traceback (most recent call last) &lt;ipython-input-11-d7ac765498dd&gt; in &lt;module&gt;() -&gt; 1 A,_,C=range(10) 2 print(&#39;A= &#39;,A) 3 #print(&#39;B= &#39;,B) 4 print(&#39;C= &#39;,C) ValueError: too many values to unpack (expected 3) . A,_=(1,(1,2,3,4)) print(A) . 1 . _,A=(1,(1,2,3,4)) print(A) print(A[0]) . (1, 2, 3, 4) 1 . Defining and using a named tuple type . from collections import namedtuple # To Intialize a namedtuple two parameters are required. # First parameter is a class name and second one is a list of field names # which are given as a string in the following form. Employee = namedtuple(&#39;employee&#39;,&#39;IDno Position Department Pay Years_of_service&#39;) Employee . __main__.employee . E1=Employee(1123,&#39;D&#39;,&#39;Analytics&#39;,30000,1) type(E1) . __main__.employee . # in the global scope when we intialize the employee # named tuple object employee.IDno(E1) . NameError Traceback (most recent call last) &lt;ipython-input-16-cdf25349993c&gt; in &lt;module&gt;() 3 # named tuple object 4 -&gt; 5 employee.IDno(E1) NameError: name &#39;employee&#39; is not defined . print(E1.IDno) print() print(E1.Position) print() print(E1.Department) print() print(E1.Pay) . 1123 D Analytics 30000 . info = (11135,&#39;D&#39;,&#39;HR&#39;,5666666,55) E2=Employee._make(info) . E2 . employee(IDno=11135, Position=&#39;D&#39;, Department=&#39;HR&#39;, Pay=5666666, Years_of_service=55) . # a mapping object Employee._asdict(E2) . OrderedDict([(&#39;IDno&#39;, 11135), (&#39;Position&#39;, &#39;D&#39;), (&#39;Department&#39;, &#39;HR&#39;), (&#39;Pay&#39;, 5666666), (&#39;Years_of_service&#39;, 55)]) .",
            "url": "https://varadan13.github.io/import_this/python_notes/2021/04/16/_04_16_LRCH1.html",
            "relUrl": "/python_notes/2021/04/16/_04_16_LRCH1.html",
            "date": " • Apr 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Please have a PCA refresher",
            "content": "Section 0 . Codes and fetching data . import pandas as pd import numpy as np import statsmodels.api as sm import tabulate as tb # to draw tables class udregression(object): &quot;&quot;&quot;udregression stands for a class that is user defined to do regression&quot;&quot;&quot; def __init__(self,X,Y,intercept=True): self.X=X self.Y=Y self.intercept=intercept def fit_model(self): if self.intercept==True: X1=np.column_stack([[1 for _ in range(self.X.shape[0])],self.X]) model=sm.OLS(self.Y,X1) f_model=model.fit() else: model=sm.OLS(self.Y,self.X) f_model=model.fit() return f_model def print_result(self): fitted_model=self.fit_model() length=len(fitted_model.summary().tables[1].data) var=[i[0] for i in fitted_model.summary().tables[1].data[1:length]] prtmp1={&#39;var&#39;:var,&#39;coef&#39;:fitted_model.params, &#39;st error&#39;:fitted_model.bse,&#39;t values&#39;:fitted_model.tvalues, &#39;p values&#39;:fitted_model.pvalues,&#39;LL&#39;:fitted_model.conf_int()[:,0], &#39;RL&#39;:fitted_model.conf_int()[:,1]} prtmp2={&#39;rsquared&#39;:[fitted_model.rsquared], &#39;rsquared_Adj&#39;:[fitted_model.rsquared_adj], &#39;fvalue&#39;:[fitted_model.fvalue]} print(tb.tabulate(prtmp1,headers=&quot;keys&quot;)) print() print(tb.tabulate(prtmp2,headers=&quot;keys&quot;)) def __repr__(self): return &quot;a custom regression runner has been intialised&quot; df=pd.read_csv(&#39;https://raw.githubusercontent.com/varadan13/Data_Bank/main/Econ%20data/MULTICOLLINEARITYPROB.csv&#39;) . Section 1 . Suppose we have a data of the form $(y,x_1,x_2)$. [for now let&#39;s think about them as points in a 3D space] . let&#39;s assume $x_1$ and $x_2$ are linearly related. . Our current problem can be roughly summarised as follows: predict y &lt;- (by using information in $x_1$) &amp; (by using information in $x_2$) . (1.1) But since we assumed that $x_1$ and $x_2$ are linearly related there may not be much information remaining in $x_2$ once we regress $x_1$ on y or there may not be much information remaining in $x_1$ once we regress $x_2$ on y. . let&#39;s take an example to understand this. . Below, we have stored a data set in &#39;data&#39;. . data=df[[&#39;Hours&#39;,&#39;NEIN&#39;,&#39;Assets&#39;]] # NEIN and Assets are independent variable # Hours is dependent variable # So we are regressing NEIN and Assets on Hours # Let&#39;s check the correlation between NEIN and Assets . data[[&#39;NEIN&#39;,&#39;Assets&#39;]].corr() . NEIN Assets . NEIN 1.00000 | 0.98751 | . Assets 0.98751 | 1.00000 | . As we can see that NEIN and Assets are highly correlated. . What are we going to do to understand (1.1)? . Let&#39;s first regress NEIN on Hours | Then see if the slope is significant. | If significant let&#39;s compute the residual. | Then let&#39;s regress Assets on the residual | Check for the significance. | . What we are hoping to see is that the residual-Assets slope will be insignificant as there is very less information in Assets that we can use to explain Hours using a linear model. Why? Because Assets-NEIN are correlated. . Y=df.Hours.to_numpy() X1=df.NEIN.to_numpy() X2=df.Assets.to_numpy() regression=udregression regression(X1,Y).print_result() . var coef st error t values p values LL RL -- -- - - -- -- const 2033.84 21.0139 96.7856 4.35155e-42 1991.09 2076.59 x1 0.318879 0.0599264 5.32117 7.15058e-06 0.196958 0.4408 rsquared rsquared_Adj fvalue - -- -- 0.461794 0.445485 28.3149 . From the above results we can observe that the slopes are significant. Now let&#39;s compute the residuals and finish the above procedure. . Residual=regression(X1,Y).fit_model().predict()-Y regression(X2,Residual) #Regressing Assets with the residual #let&#39;s check the results regression(X2,Residual).print_result() . var coef st error t values p values LL RL -- -- -- - - -- const 6.56741 19.0888 0.344045 0.732995 -32.269 45.4039 x1 -0.00108075 0.00284811 -0.379463 0.706775 -0.00687527 0.00471377 rsquared rsquared_Adj fvalue - -- -- 0.00434444 -0.0258269 0.143992 . Now we can see that the slopes are insignificant. One can also reverse X1 with X2 and conclude the same. Now the question is what can we do about this problem. . Section 2 . Suppose we can create $z_1$ and $z_2$ such that . $z_1=a_{11}x_1+a_{12}x_2$ and $z_2=a_{21}x_1+a_{22}x_2$ | $V(z_{1})&gt;V(z_{2})$ | z1 and z2 are ortho normal vectors | . How to interpret the above conditions? We must interpret (1.1) and the adjoining example in a practical way. (1.1) is essentially telling us that we can do our analysis with just one variable instead of two. But that does not mean that we can abandon x1 or x2 with out incurring any error because x1 and x2 may be present in our model because of some empirical considerations. So when we extract z1 and z2 we are cleverly partitioning the variance thereby extracting orthogonal vectors that do not share any information with one another. This can be seen clearly when we generalise this derivation to a p variate problem. Now if the variance of z2 is very less we can omit it and do our analysis with just z1. .",
            "url": "https://varadan13.github.io/import_this/linear%20algebra%20tutorial/2021/04/10/PCArefresher.html",
            "relUrl": "/linear%20algebra%20tutorial/2021/04/10/PCArefresher.html",
            "date": " • Apr 10, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Basic Git Notes.",
            "content": "Configuring username and email in git . git config --global user.name &quot;varadan&quot; git config --global user.email &quot;varadan_pornhub@nic.in&quot; . To list all the git settings . git config --list . To get a specific setting. . git config user.name #for viewing user_name git config user.email . To get help. . git help #git will list all the options adjoining #help and also lists most common commands #for which help can be used with. #for example git help commit . Some system commands that will help in navigating the file system . cd ~ #changes the directory to the system home directory cd .. #changes the directory one step backwards the node pwd #lists the current working directory ls #lists all the files and directories in the cwd. clear #this clears the console . To intialise a git repository. . pwd #displays the current working directory of git cd &lt;path_to_the_directory_git_should_work_in&gt; git init #intializes a git repository in the current working directory . To commit a change to the git repository . git add . git commit -m &quot;a commit message&quot; #commit is like save the state of the #repository at this point in time. . How to view the commit history. . git log git log --author=&quot;a author of this repository&quot; . To view the current state of the repository. . git status #displays any changes that needs to added to the repository or not. . To View the modifications . git diff #differences in the working copy and the repository copy. . What is a working copy? The files we make constant edits before commiting to git is called working copy. . What is a repository copy? When we commit a file to git, git makes a copy of that file and keeps that copy with it this is called repository copy. . If a file let’s say random.txt is changed and added to the staging area, . git diff #shows no differences as this file now is in the staging area #diff only shows differences in the working copy and the repository #copy git diff --staged #this command will show differences in the files #repository and the staging area . To remove a file from working area. . git rm &lt;name_of_the_file&gt; git commit -m &quot;a message&quot; . To rename a file. . Method 1 . Add a new file then delete the old file == renaming the old file . git add &lt;a_new_file_name&gt; git rm &lt;a_old_file_name&gt; git commit -m &quot;a commit message&quot; . Method 2 . Renaming a file. In Git renaming a file == moving a file to a new file in the same location . git mv &lt;name_of_the_old_file&gt; &lt;name_of_the_new_file&gt; git commit -m &quot;commit message&quot; . Moving a file in Git . git mv &lt;name_of_the_old_file&gt; &lt;file_destination name_of_the_new_File&gt; git commit -m &quot;commit message&quot; . To add and commit in one go . git commit -am &quot;a commit message&quot; . Git checkout . git checkout -- &lt;name of the file&gt; #checkout is a way to tell #git to take the &lt;name of the file&gt; file #from the repository #and put that in the working area. #What does -- mean? #it tells git that the name given to checkout #is not a branch #note:- a space is present after --. git commit -m &quot;message&quot; . Unstaging a file. . What is unstaging? it is to tell to git to remove a file from the staging area. . git reset HEAD &lt;name of the file to remove from staging area&gt; . To get old version of the project. . git checkout &lt;first few charachters of commit number&gt; -- &lt;name of the file&gt; git commit -m &quot;a commit message&quot; .",
            "url": "https://varadan13.github.io/import_this/git%20github%20notes/2021/04/09/git-notes-basic.html",
            "relUrl": "/git%20github%20notes/2021/04/09/git-notes-basic.html",
            "date": " • Apr 9, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Code Snippets to practise context managers and a quirky behaviour of functions",
            "content": "def a_simple_context_func(file_address,message,shld_write=True): file=open(file_address,&quot;wt&quot;) if shld_write==True: file.__enter__() file.write(message) file.__exit__() . Context=a_simple_context_func(&quot;/content/sample_data/README.md&quot;,&quot;a simple message to write&quot;) . OR . file=open(&quot;/content/sample_data/README.md&quot;,&quot;wt&quot;) file.__enter__() file.write(&quot;a second message to write&quot;) file.__exit__() . AND THEN . file.write(&quot;a third message that won&#39;t write cus the file is closed&quot;) . ValueError Traceback (most recent call last) &lt;ipython-input-4-2aaf5c7439bd&gt; in &lt;module&gt;() -&gt; 1 file.write(&#34;a third message that won&#39;t write cus the file is closed&#34;) ValueError: I/O operation on closed file. . USING with . with open(&quot;/content/sample_data/README.md&quot;,&quot;wt&quot;) as file: file.write(&quot;fourth message to write using with&quot;) . file # still exists but the connection is closed . &lt;_io.TextIOWrapper name=&#39;/content/sample_data/README.md&#39; mode=&#39;wt&#39; encoding=&#39;UTF-8&#39;&gt; . file.write(&quot;xyx&quot;) . ValueError Traceback (most recent call last) &lt;ipython-input-7-10bc188c1ce1&gt; in &lt;module&gt;() -&gt; 1 file.write(&#34;xyx&#34;) ValueError: I/O operation on closed file. . In Python, the attributes attached to a function will differ based on the return value of that function. . For example, simplet function just returns the parameter. So if the parameter is a string type then the return value of function will have attributes of string type and likewise for float type, interger type parameters. . def simplet(x): return x . A=simplet(1) B=simplet(&quot;string&quot;) C=simplet(1000.2324) . dir(A)==dir(B) . False . dir(A)==dir(C) . False . A_func=simplet B_func=simplet . dir(A_func)==dir(B_func) . True . set(dir(C))-set(dir(A)) . {&#39;__getformat__&#39;, &#39;__set_format__&#39;, &#39;as_integer_ratio&#39;, &#39;fromhex&#39;, &#39;hex&#39;, &#39;is_integer&#39;} .",
            "url": "https://varadan13.github.io/import_this/python_notes/2021/04/09/codesnippet-contextmanag.html",
            "relUrl": "/python_notes/2021/04/09/codesnippet-contextmanag.html",
            "date": " • Apr 9, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Instance and class variable notes.",
            "content": "Instance Variable . Instance variables are owned by instances of the class. | This means that for each object or instance of a class, the instance variables are different. | Unlike class variables, instance variables are defined within methods. . class Potterhead(object): def __init__(self,movie): self.movie = movie #instance variable . | . Class Variable . Class variables are defined within the class construction. | Because they are owned by the class itself, class variables are shared by all instances of the class. . class PotterHead(object): hero=&quot;Dumbeldore&quot; # class variable . | . Different ways to access Instance Variable in Python . There are two ways to access the instance variable of class: . Within the class by using self and object reference. | Using getattr() method | .",
            "url": "https://varadan13.github.io/import_this/python_notes/2021/04/08/instance-classvar.html",
            "relUrl": "/python_notes/2021/04/08/instance-classvar.html",
            "date": " • Apr 8, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Python executes class body at definition time",
            "content": "class foo: print(&quot;hello batman&quot;) . hello batman . def foo_func(): print(&quot;hello batman&quot;) . foo_func() . hello batman . While executing class body, python evaluates various expressions** inside the class body and stores it in the local name space. | This is done because that namespace then forms the class attributes. | Class bodies are not the only such namespaces; set and dict comprehensions, and in Python 3, list comprehensions are also executed with a separate namespace, scoping their locals. | . ** These expressions could be anything that we write inside the class body such as class variable, instance variable, methods etc . Why does python behave differently for functions? . Basically it fetches the instructions in the definition and stores it to the global variable(if the function is defined in the global scope) taking the value equal to its name. .",
            "url": "https://varadan13.github.io/import_this/python_notes/2021/04/06/pythonnotes1.html",
            "relUrl": "/python_notes/2021/04/06/pythonnotes1.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Introduction to Iterators and Iterables in Python",
            "content": "In Python programming from the very existence of the words &#39;iterator&#39; and &#39;iterable&#39; we must confirm that these words embody two distinct concepts and we must be clear about their differences. . As a first approximation, we can say that any object that works in a &quot;for loop&quot; is an iterable and within the &quot;for loop&quot; that object is converted to an iterator by the Python interpretor. . Let&#39;s get a little deeper. . To refine the above definition let us discuss how Python creates an iterator out of an object x.(what is happening in a for loop) . To create an iterator Python first calls iter built in function on x and this function checks the following: . whether the object implements $__iter__$ and calls that to obtain an iterator | if not, checks, if the object implements $__getitem__$ and calls that to obtain an iterator | if not Python raises TypeError, usually saying &quot;&#39;C&#39; object is not iterable&quot;, where C is the class of the target object. | import reprlib import re RE=re.compile(&#39; w+&#39;) class sentence: def __init__(self,text): self.text=text self.words=RE.findall(text) def __getitem__(self,index): return self.words[index] def __len__(self): return len(self.words) def __repr__(self): return &quot;sentence(%s)&quot;%reprlib.repr(self.text) . Let&#39;s check if the class sentence is an iterable or not. . iter(sentence(&quot;ABCD Nice Song&quot;)) . &lt;iterator at 0x7f3dabbb1710&gt; . We can see that it is indeed an iterable. The reason being that this class implements $__getitem__$ and also that iter does not return a TypeError. Now let&#39;s see what will happen if the $__getitem__$ is not implemented within this class. . import reprlib import re RE=re.compile(&#39; w+&#39;) class sentence: def __init__(self,text): self.text=text self.words=RE.findall(text) def __len__(self): return len(self.words) def __repr__(self): return &quot;sentence(%s)&quot;%reprlib.repr(self.text) iter(sentence(&quot;ABCD Nice Song&quot;)) . TypeError Traceback (most recent call last) &lt;ipython-input-43-b496195abce1&gt; in &lt;module&gt;() 12 return &#34;sentence(%s)&#34;%reprlib.repr(self.text) 13 &gt; 14 iter(sentence(&#34;ABCD Nice Song&#34;)) TypeError: &#39;sentence&#39; object is not iterable . Since $__getitem__$ is not implemented iter returns a TypeError as we have learnt before. . Let&#39;s redefine an iterable: any object from which the iter built in function can obtain an iterator is called as an iterable. . Behind the curtain, within a &quot;for loop&quot; iterables gets converted to an iterator. . Let&#39;s see an example: In the following snippets the first one is just iterating through a given string &#39;s&#39; which is an iterable and behind the curtain within the for loop it becomes an iterator, in the second snippet it becomes clear how &#39;s&#39; is converted to an iterator and also we can attempt to define an iterator. . s=&#39;ABC&#39; # Here, s is an iterable for char in s: # Here, s gets converted to an iterator print(char) . A B C . s=&#39;ABC&#39; it=iter(s) # checks if s is an iterable, if so returns an iterator instance derived from s. while True: try: print(next(it)) # Repeatedly calling next on the iterator to obtain the next item. except StopIteration: # when no next item present in the iterator next returns StopIteration. del it break . A B C . [Try defining a iterator now!] . To summarise the discussion on iterable and iterator let&#39;s discuss Fig 1 given below. . Fig 1 . From fig 1 we can observe that from an iterable object an iterator is generated using $__iter__$ and the iterator has two methods defined in it which are:$__next__$ (that allows us to loop through it) and $__iter__$ (why should we define an iter here?) Notice that the $__iter__$s in iterable and iterator are different in that for the iterator it just returns an instance of it but for an iterable it returns an iterator. . One thing this design does is that all iterators are also iterable. . Definition of iterators:- Any object that implements the $__next__$ no argument method which returns the next item in a series or raises StopIteration when there are no more items. Python iterators also implement the $__iter__$ method so they are iterable as well . Definition of iterables:- Any object from which the iter built in function can obtain an iterator is called as an iterable or a class that implements $__inter__$ method or $__getitem__$ method. . Finally let&#39;s look at an example and correlate it with the workings shown in fig 1. . import reprlib import re RE=re.compile(&#39; w+&#39;) class Sentence: def __init__(self,text): self.text=text self.words=RE.findall(text) def __repr__(self): return &quot;sentence(%s)&quot;%reprlib.repr(self.text) def __iter__(self): return SentenceIterator(self.words) class SentenceIterator: def __init__(self,words): self.words=words self.index=0 def __next__(self): try: word=self.words[self.index] except IndexError: raise StopIteration() self.index+=1 return word def __iter__(self): return self . Let&#39;s check if a sentence object is iterable or not . iter(Sentence(&quot;Hello World&quot;)) . &lt;__main__.SentenceIterator at 0x7f3dabb0e910&gt; . So it is iterable. Let&#39;s create an iterator from a Sentence object . s=Sentence(&quot;Hello World&quot;) it=iter(s) . We can see from the class definiton above that SentenceIterator is also an iterable object. Let&#39;s run the above &#39;it&#39; through a while loop. . while True: try: print(next(it)) except StopIteration: del it break . Hello World . for i in s: print(i) . Hello World . [i for i in s] . [&#39;Hello&#39;, &#39;World&#39;] .",
            "url": "https://varadan13.github.io/import_this/python_notes/2021/04/06/iterators-iterables.html",
            "relUrl": "/python_notes/2021/04/06/iterators-iterables.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Eigen values and Eigen vectors",
            "content": "Learning objectives . To define eigen values and vectors and state some of their properties | To factorize a square matrix $A$ into $S Lambda S^{-1}$. | Factorizing a symmetric matrix | Spectral theorem | Positive definite matrices | Singular value decomposition | . Section 1: Basics . Let A be a matrix and x be a vector. How to interpret Ax? If Ax is possible then Ax is a vector in a space spanned by the columns of A(column space of A). So another way to look at it is that A transforms vector x (i.e., change of scale, direction) into a vector y (=Ax) which lies in the column space of A. . Eigen vectors are a special type of vectors where they don&#39;t change direction but their length changes when multiplied with A OR Eigen vectors are those vectors that satisfies the equation $Ax= lambda x$ where $ lambda$ can be a fraction, any integer etc. The number $ lambda$ is the eigen value. . Note- Let $A = I$ where $I$ is the identity matrix. For A, all vector x is an Eigen vector with eigen value = 1. . Example . Lets illustrate the above definition using the example below . $Ax = begin{pmatrix} .8 &amp; .3 .2 &amp; .7 end{pmatrix}x= lambda x$ | Here to extract the eigen values we must solve the following equation. . $(A- lambda I)x=0 $ if the eigen value exist then the determinat of $A- lambda I$ must be equal to zero. (why?) . Therefore the equation we must solve here (after all simplification) equals $2 lambda ^2-3 lambda +1 =0$ , we get $ lambda = 1,1/2$ and substituting for $ lambda$ in 1 we can extract the corresponding eigen vectors and they are . $x= begin{pmatrix}.6 .4 end{pmatrix}, lambda = 1$ &amp; $x= begin{pmatrix}1 -1 end{pmatrix}, lambda = 1/2$ . Let us think about the geometry of eigen vectors. when x is multiplied with A the eigen vector with $ lambda$ value = 1 stays the same in direction and in length but for $ lambda$ = 1/2 that eigen vectors magnitude halves. . Elimination does not perserve the $ lambda$s | The product of n eigen values equals the determinant of the matrix | The sum of n eigen values is equal to the sum of the diagonal values of a matrix which is called the trace of the matrix. | One of the many applications of eigen values is that they help in computing large powers of a given matrix(what type of matrix?) i.e., Let&#39;s say $A^{100}$ | . Finding eigen values and vectors in python . import numpy as np . A=np.array([[1,2,1],[3,5,2],[4,3,4]]) print(A) . [[1 2 1] [3 5 2] [4 3 4]] . eigen_values,eigen_vectors=np.linalg.eig(A) #the obtained eigen vectors are unit vectors. . print(eigen_values) . [ 8.37685015 -0.30893252 1.93208237] . print(eigen_vectors) # i th row represent the eigen vector of the respective # i th eigen value . [[-0.27355094 -0.78788511 -0.09183165] [-0.65834893 0.23001831 -0.47923262] [-0.70124644 0.57125181 0.87287058]] . Trace=A[0][0]+A[1][1]+A[2][2] sum_of_eigen_values = round(np.sum(eigen_values),1) print(&quot;trace of the matrix A = &quot;,float(Trace)) print(&quot;Sum of the eigen values of A = &quot;,sum_of_eigen_values) . trace of the matrix A = 10.0 Sum of the eigen values of A = 10.0 . To show that elimination does not perserve $ lambda$s. . Let P be a permutation matrix. P reduces row 2 by subtracting the values in row 2 with the corresponding values in row 1 multiplied by 3. . P=np.array([[1,0,0],[-3,1,0],[0,0,1]]) . print(P@A) . [[ 1 2 1] [ 0 -1 -1] [ 4 3 4]] . B=P@A . eig_values_B,eig_vectors=np.linalg.eig(B) . print(&quot;eigen values of A after elimination = &quot;,eig_values_B) print(&quot;eigen values of A bfore elimination = &quot;,eigen_values) . eigen values of A after elimination = [ 4.1925824 1. -1.1925824] eigen values of A bfore elimination = [ 8.37685015 -0.30893252 1.93208237] . $(A- lambda I)x=0 $ if the eigen value exist then the determinat of $A- lambda I$ must be equal to zero. (why?) . Basically, if there exist a x other than the trivial zero/null vector it means that the null space spanned by $A- lambda I$ contains vectors other than the null vector and also implies that the vectors sitting in the columns of $A- lambda I$ are dependent which means the matrix don&#39;t have full column rank which implies that determinant of $A- lambda I$ is equal to zero. . Summary . An eigenvector or characteristic vector of a linear transformation (read Matrix for now) is a nonzero vector that changes at most by a scalar factor when that linear transformation is applied to it. | The sum and product of the A&#39;s equal the trace and delerminant of A respectively | Elimination does not perserve the λs | . Note The eigenvalues of $A^2$ &amp; $A^{-1}$ are $ lambda ^2$ &amp; $ lambda ^{-1}$ respectively . Note if x is an eigen vector of A then Ax is simply reduced to $ lambda x$. Similarly, AAx=$ lambda lambda x$. We can generalise it as $A^{n}x= lambda ^{n}x$ where x is an eigen vector . Section 2 : Diagonalizing a matrix using Eigen vectors . (2.1) Suppose the n by n matrix A has n linearly independent eigen vectors $x_1,x_2,...,x_n$ and S be a matrix whose columns contains these n independent eigen vectors then $S^{-1}AS = Lambda$ where $ Lambda$ is eigen value matrix of A and also diagonalized matrix of A. . What is the Eigen Value Matrix of A? A matrix that contains eigen values of A in its diagonal position with off diagonal entry equals to zero. . Let&#39;s use (2.1) to rewrite A in a more meaningful way. From (2.1) $S^{-1}AS = Lambda$ which implies that $AS=S Lambda$ and this can be written as $A=S Lambda S^{-1}$. . (2.2) $A=S Lambda S^{-1}$ iff eigen vectors are linearly independent. OR in other words all the eigen vectors are unique. Matrices with repeated eigen values cannot be factorised into this form because S will not be invertible(why?) . Note S is not a unique matrix (why?) . What is the meaning of (2.2)? How can we use it? Let A be a matrix that can be factorised into (2.2) now it becomes easy to compute $A^{n}$ because $A^{n}=S Lambda^{n} S^{-1}$ . def check_uniqueness(eigen_value): checker=[i for i in range(0,len(eigen_value)-1) for j in range(i+1,len(eigen_value)) if eigen_value[i]==eigen_value[j]] if len(checker)==0: return &#39;UNIQUE&#39; else: return &#39;NOT UNIQUE&#39; . def diagonalizer(A): eigen_value,w=np.linalg.eig(A) if check_uniqueness(eigen_value)==&#39;UNIQUE&#39;: return np.round(np.linalg.inv(w)@(A@w),3) else: print(&quot;Sorry the matrix does not have unique eigen values&quot;) . A=np.array([[1,2,1],[3,5,2],[4,3,4]]) e,_=np.linalg.eig(A) print(diagonalizer(A)) print() print(&quot;the eigen values of the Matrix A = &quot;, e) . [[ 8.377 -0. -0. ] [ 0. -0.309 0. ] [ 0. 0. 1.932]] the eigen values of the Matrix A = [ 8.37685015 -0.30893252 1.93208237] . Setion 3:Diagonalizing a symmetric matrix . 3.1 Definition A is a symmetric matrix if $A=A^{T}$ . Let&#39;s explore using an example . $sys = begin{pmatrix} 5 &amp; 6 &amp; 7 6 &amp; 3 &amp; 2 7 &amp; 2 &amp; 1 end{pmatrix}$ we can see that sys is a 3*3 symmetric matrix. . sys = np.array([[5,6,7],[6,3,2],[7,2,1]]) # Let&#39;s check if the eigen values of sys matrix is unique or not eig,_=np.linalg.eig(sys) check_uniqueness(eig)==&#39;UNIQUE&#39; . True . Therefore eigen values of sys matrix is unique. . Let&#39;s check out the eigen vector matrix of sys . eig,S=np.linalg.eig(sys) print(&quot;the eigen vector matrix of sys = n&quot;, S) . the eigen vector matrix of sys = [[ 0.72541697 0.66666667 0.17124772] [ 0.49566405 -0.33333333 -0.80200127] [ 0.47758494 -0.66666667 0.57224835]] . What are the properties of S? . eig_vec1,eig_vec2,eig_vec3=S[:,0],S[:,1],S[:,2] . round(np.dot(eig_vec1,eig_vec2),3) . -0.0 . round(np.dot(eig_vec2,eig_vec3),3) . 0.0 . round(np.dot(eig_vec3,eig_vec1),3) . -0.0 . The first thing therefore we notice is that the eigen vectors are orthogonal to each other . np.round(S@S.T,3) . array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) . np.round(S.T@S,3) . array([[ 1., 0., -0.], [ 0., 1., 0.], [-0., 0., 1.]]) . The second thing we notice is that the inverse of eigen vector matrix is its transpose therefore eigen vector matrix of a symmetric matrix is an orthogonal matrix . (3.2) Definition Orthogonal matrix An orthogonal matrix is a real square matrix whose columns and rows are orthogonal vectors OR $M*M^{-1}=I$ where M is the orthogonal matrix. . Here, the eigen vector matrix is not only orthogonal but also orthonormal because numpy normalises the obtained eigen vectors into unit vectors. . For example:- . round(np.dot(eig_vec1,eig_vec1),3) . 1.0 . What are the properties of S? i.e., eigen vector matrix of a symmetric matrix . eigen vectors are orthogonal to each other | the inverse of eigen vector matrix is its transpose therefore eigen vector matrix of a symmetric matrix is an orthogonal matrix | if the eigen vectors are unit vectors then the eigen vector matrix is an orthonormal matrix. | . Now let&#39;s answer the question, what is the form of matrix diagonalisation when the matrix is symmetric? . $S^{-1}AS= Lambda$ this is when A is non symmetric when A is symmetric the equation becomes $S^{T}AS= Lambda$ . This journey culminates with the spectral theorem . (3.3) Spectral theorem Every symmetric matrix A can be factorised as $S Lambda S^{T}$ with $ Lambda$ matrix holding real eigen values in its diagonal position and orthonormal eigen vectors sitting in the columns of S matrix. . Summary of Section 2 and 3 . We have learnt that A can be factorised into $A=S Lambda S^{-1}$ | This factorisation can be used to seamlessly compute $A^{n}$ by using the following formula $A^{n}=S Lambda^{n} S^{-1}$. | . Section 4: Positive definite &amp; Singular Value Decomposition . (4.1) Definition Positive definite matrix A symmetric matrix whose eigen values are all positive . How to test for positive definitness? The matrix A is positive definite if $x^{T}Ax&gt;0$ for all nonzero vector X .",
            "url": "https://varadan13.github.io/import_this/linear%20algebra%20tutorial/2021/03/26/EIGEN-VALUE.html",
            "relUrl": "/linear%20algebra%20tutorial/2021/03/26/EIGEN-VALUE.html",
            "date": " • Mar 26, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Become the teacher I never had .",
          "url": "https://varadan13.github.io/import_this/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://varadan13.github.io/import_this/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}