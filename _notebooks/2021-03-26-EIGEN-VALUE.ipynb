{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear algera.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnleM3Gs0JDI"
      },
      "source": [
        "# Eigen values and Eigen vectors\n",
        "\n",
        "> Topics covered-Basics,Diagonalizing a square matrix, Spectral theorem, Positive definite matrix, SVD. \n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [Linear Algebra Tutorial]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoHdRyLvEZz1"
      },
      "source": [
        "> Learning objectives  \n",
        "- To define eigen values and vectors and state some of their properties \n",
        "- To factorize a square matrix $A$ into $S \\Lambda S^{-1}$.\n",
        "- Factorizing a symmetric matrix\n",
        "- Spectral theorem\n",
        "- Positive definite matrices\n",
        "- Singular value decomposition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6q-rtjR0XeO"
      },
      "source": [
        "## Section 1: Basics\n",
        "\n",
        "Let A be a matrix and x be a vector. How to interpret Ax? If Ax is possible then Ax is a vector in a space spanned by the columns of A(column space of A). So another way to look at it is that A transforms vector x (i.e., change of scale, direction) into a vector y (=Ax) which lies in the column space of A.\n",
        "\n",
        "Eigen vectors are a special type of vectors where they don't change direction but their length changes when multiplied with A OR Eigen vectors are those vectors that satisfies the equation $Ax=\\lambda x$ where $\\lambda$ can be a fraction, any integer etc. The number $\\lambda$ is the eigen value.\n",
        "\n",
        "**Note**- Let $A = I$ where $I$ is the identity matrix. For A, all vector x is an Eigen vector with eigen value = 1. \n",
        "\n",
        "**Example**\n",
        "\n",
        "Lets illustrate the above definition using the example below\n",
        "\n",
        "1. $Ax = \\begin{pmatrix} .8 & .3 \\\\ .2 & .7 \\end{pmatrix}x=\\lambda x$\n",
        "\n",
        "Here to extract the eigen values we must solve the following equation.\n",
        "\n",
        "$(A-\\lambda I)x=0 $ if the eigen value exist then the determinat of $A-\\lambda I$ must be equal to zero. (why?)\n",
        "\n",
        "Therefore the equation we must solve here (after all simplification) equals $2 \\lambda ^2-3 \\lambda +1 =0$ , we get $\\lambda = 1,1/2$ and substituting for $\\lambda$ in 1 we can extract the corresponding eigen vectors and they are    \n",
        "\n",
        "$x=\\begin{pmatrix}.6\\\\.4\\end{pmatrix}, \\lambda = 1$  \n",
        "&    \n",
        "$x=\\begin{pmatrix}1\\\\-1\\end{pmatrix}, \\lambda = 1/2$\n",
        "\n",
        "Let us think about the geometry of eigen vectors. when x is multiplied with A the eigen vector with $\\lambda$ value = 1 stays the same in direction and in length but for $\\lambda$ = 1/2 that eigen vectors magnitude halves. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOMKeKI1G-Cp"
      },
      "source": [
        "- **Elimination does not perserve the $\\lambda$s**\n",
        "- The product of n eigen values equals the determinant of the matrix\n",
        "- The sum of n eigen values is equal to the sum of the diagonal values of a matrix which is called the trace of the matrix.\n",
        "- One of the many applications of eigen values is that they help in computing large powers of a given matrix(what type of matrix?) i.e., Let's say $A^{100}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCF6sAS4Ji--"
      },
      "source": [
        "**Finding eigen values and vectors in python**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A82eYWDj_7Oo"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W--WBV3K0NGq",
        "outputId": "133c27a2-a399-46a4-bb69-e21334da6a2f"
      },
      "source": [
        "A=np.array([[1,2,1],[3,5,2],[4,3,4]])\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 1]\n",
            " [3 5 2]\n",
            " [4 3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DEEzuRXKQiX"
      },
      "source": [
        "eigen_values,eigen_vectors=np.linalg.eig(A) #the obtained eigen vectors are unit vectors."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U2beIR7LFAD",
        "outputId": "4368c062-ae26-4674-b6d0-0b243565b938"
      },
      "source": [
        "print(eigen_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8.37685015 -0.30893252  1.93208237]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93cKCTM8MLMA",
        "outputId": "d0b9ef90-819a-496d-f627-c21ae4ebf584"
      },
      "source": [
        "print(eigen_vectors) # i th row represent the eigen vector of the respective \n",
        "                     # i th eigen value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.27355094 -0.78788511 -0.09183165]\n",
            " [-0.65834893  0.23001831 -0.47923262]\n",
            " [-0.70124644  0.57125181  0.87287058]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45dBkXA3QESg",
        "outputId": "2ab1f148-69e9-4c7d-9a91-cbd7088b9fc5"
      },
      "source": [
        "Trace=A[0][0]+A[1][1]+A[2][2]\n",
        "sum_of_eigen_values = round(np.sum(eigen_values),1)\n",
        "print(\"trace of the matrix A = \",float(Trace))\n",
        "print(\"Sum of the eigen values of A = \",sum_of_eigen_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trace of the matrix A =  10.0\n",
            "Sum of the eigen values of A =  10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw2cJ1EZSG6h"
      },
      "source": [
        "**To show that elimination does not perserve $\\lambda$s.** \n",
        "\n",
        "Let P be a permutation matrix. P reduces row 2 by subtracting the values in row 2 with the corresponding values in row 1 multiplied by 3.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueC0MRAwQ2j_"
      },
      "source": [
        "P=np.array([[1,0,0],[-3,1,0],[0,0,1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYAZlId9R_YK",
        "outputId": "3bfa4caf-b145-4e44-8094-f2af5289b2f9"
      },
      "source": [
        "print(P@A) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  1]\n",
            " [ 0 -1 -1]\n",
            " [ 4  3  4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40g6_kKXSBb7"
      },
      "source": [
        "B=P@A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYPV6MKS5gc"
      },
      "source": [
        "eig_values_B,eig_vectors=np.linalg.eig(B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_2tIh2ATDhJ",
        "outputId": "367d5725-1b3d-4d29-b349-e8642b564358"
      },
      "source": [
        "print(\"eigen values of A after elimination = \",eig_values_B)\n",
        "print(\"eigen values of A bfore elimination = \",eigen_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eigen values of A after elimination =  [ 4.1925824  1.        -1.1925824]\n",
            "eigen values of A bfore elimination =  [ 8.37685015 -0.30893252  1.93208237]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtK7P_l9V2Y5"
      },
      "source": [
        "$(A-\\lambda I)x=0 $ if the eigen value exist then the determinat of $A-\\lambda I$ must be equal to zero. (why?)\n",
        "\n",
        "Basically, if there exist a x other than the trivial zero/null vector it means that the null space spanned by $A-\\lambda I$ contains vectors other than the null vector and also implies that the vectors sitting in the columns of $A-\\lambda I$  are dependent which means the matrix don't have full column rank which implies that determinant of $A- \\lambda I$ is equal to zero. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waFDw1c4Xq0O"
      },
      "source": [
        "> Summary  \n",
        "- An eigenvector or characteristic vector of a linear transformation (read Matrix for now) is a nonzero vector that changes at most by a scalar factor when that linear transformation is applied to it.\n",
        "- The sum and product of the A's equal the trace and delerminant of A respectively\n",
        "- Elimination does not perserve the Î»s\n",
        "\n",
        "**Note** The eigenvalues of $A^2$ & $A^{-1}$ are $\\lambda ^2$ & $\\lambda ^{-1}$ respectively\n",
        "\n",
        "**Note**  \n",
        "if x is an eigen vector of A then Ax is simply reduced to $\\lambda x$. Similarly, AAx=$\\lambda \\lambda x$.      \n",
        "We can generalise it as $A^{n}x=\\lambda ^{n}x$ where x is an eigen vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgb4ETTssaFM"
      },
      "source": [
        "## Section 2 : Diagonalizing a matrix using Eigen vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8wu14d7sf0T"
      },
      "source": [
        "(2.1) Suppose the n by n matrix A has n **linearly independent eigen vectors** $x_1,x_2,...,x_n$ and S be a matrix whose columns contains these n independent eigen vectors then $S^{-1}AS = \\Lambda$ where $\\Lambda$ is eigen value matrix of A and also diagonalized matrix of A.\n",
        "\n",
        "**What is the Eigen Value Matrix of A?**    \n",
        "A matrix that contains eigen values of A in its diagonal position with off diagonal entry equals to zero.\n",
        "\n",
        "Let's use (2.1) to rewrite A in a more meaningful way. From (2.1) $S^{-1}AS = \\Lambda$ which implies that $AS=S\\Lambda$ and this can be written as $A=S \\Lambda S^{-1}$.\n",
        "\n",
        "(2.2) $A=S \\Lambda S^{-1}$ iff eigen vectors are linearly independent. OR in other words all the eigen vectors are unique. Matrices with repeated eigen values cannot be factorised into this form because S will not be invertible(why?)\n",
        "\n",
        "**Note** S is not a unique matrix (why?)\n",
        "\n",
        "**What is the meaning of (2.2)? How can we use it?**  \n",
        "Let A be a matrix that can be factorised into (2.2) now it becomes easy to compute $A^{n}$ because $A^{n}=S \\Lambda^{n} S^{-1}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZMEKFyxTYaI"
      },
      "source": [
        "def check_uniqueness(eigen_value):\n",
        "  checker=[i for i in range(0,len(eigen_value)-1) for j in range(i+1,len(eigen_value)) if eigen_value[i]==eigen_value[j]]\n",
        "  if len(checker)==0:\n",
        "    return 'UNIQUE'\n",
        "  else:\n",
        "    return 'NOT UNIQUE'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRDY7P0rypl5"
      },
      "source": [
        "def diagonalizer(A):\n",
        "  eigen_value,w=np.linalg.eig(A)\n",
        "  if check_uniqueness(eigen_value)=='UNIQUE':\n",
        "    return np.round(np.linalg.inv(w)@(A@w),3)\n",
        "  else:\n",
        "    print(\"Sorry the matrix does not have unique eigen values\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytAoXaz-zC0x",
        "outputId": "b9c7ce94-3c07-48ca-d342-62c5f9be3ff2"
      },
      "source": [
        "A=np.array([[1,2,1],[3,5,2],[4,3,4]])\n",
        "e,_=np.linalg.eig(A)\n",
        "print(diagonalizer(A))\n",
        "print()\n",
        "print(\"the eigen values of the Matrix A = \", e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8.377 -0.    -0.   ]\n",
            " [ 0.    -0.309  0.   ]\n",
            " [ 0.     0.     1.932]]\n",
            "\n",
            "the eigen values of the Matrix A =  [ 8.37685015 -0.30893252  1.93208237]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVp6O32-HksS"
      },
      "source": [
        "### Setion 3:Diagonalizing a symmetric matrix\n",
        "\n",
        "3.1 **Definition**   \n",
        "A is a symmetric matrix if $A=A^{T}$\n",
        "\n",
        "Let's explore using an example\n",
        "\n",
        "$sys = \\begin{pmatrix} 5 & 6 & 7\\\\ 6 & 3 & 2\\\\7 & 2 & 1 \\end{pmatrix}$ we can see that sys is a 3*3 symmetric matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSJGbanifbP4",
        "outputId": "0e906b62-6b25-4fb7-bb38-f53fad5c72e6"
      },
      "source": [
        "# intialising sys as a numpy array\n",
        "sys = np.array([[5,6,7],[6,3,2],[7,2,1]])\n",
        "# Let's check if the eigen values of sys matrix is unique or not\n",
        "eig,_=np.linalg.eig(sys)\n",
        "check_uniqueness(eig)=='UNIQUE'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbh2gtPUgUA-"
      },
      "source": [
        "Therefore eigen values of sys matrix is unique. \n",
        "\n",
        "Let's check out the eigen vector matrix of sys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl7Xx_Y6huEz",
        "outputId": "8745974c-f6aa-48be-ea1f-61b74a235776"
      },
      "source": [
        "eig,S=np.linalg.eig(sys)\n",
        "print(\"the eigen vector matrix of sys = \\n\", S)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the eigen vector matrix of sys = \n",
            " [[ 0.72541697  0.66666667  0.17124772]\n",
            " [ 0.49566405 -0.33333333 -0.80200127]\n",
            " [ 0.47758494 -0.66666667  0.57224835]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ha5wTe8iCyb"
      },
      "source": [
        "**What are the properties of S?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd9gnO2AiB1o"
      },
      "source": [
        "eig_vec1,eig_vec2,eig_vec3=S[:,0],S[:,1],S[:,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuvBc3YPinGk",
        "outputId": "e68dcacc-5081-46e3-a623-ce0aa220c023"
      },
      "source": [
        "# Let's  find out the dot product of the three eigen vectors among themselves\n",
        "round(np.dot(eig_vec1,eig_vec2),3) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soarWP6Di5eu",
        "outputId": "cc0f9a4f-5628-44e1-8e8b-3cbb6559bd1a"
      },
      "source": [
        "round(np.dot(eig_vec2,eig_vec3),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPYiTzZei-4I",
        "outputId": "c45c1a70-e86b-4485-edcf-4b05a3dc6ca9"
      },
      "source": [
        "round(np.dot(eig_vec3,eig_vec1),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9lfLpmjTWB"
      },
      "source": [
        "The first thing therefore we notice is that the eigen vectors are orthogonal to each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMWtf7IyjRV7",
        "outputId": "2602a307-936d-4a5d-ada7-beaa2634aede"
      },
      "source": [
        "np.round(S@S.T,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHuAlhdNjrSZ",
        "outputId": "79947162-8d18-47f8-e2ef-f8be7d5f7809"
      },
      "source": [
        "np.round(S.T@S,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  0., -0.],\n",
              "       [ 0.,  1.,  0.],\n",
              "       [-0.,  0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRpOWokdjwJA"
      },
      "source": [
        "The second thing we notice is that the inverse of eigen vector matrix is its transpose therefore eigen vector matrix of a symmetric matrix is an orthogonal matrix\n",
        "\n",
        "(3.2) **Definition** Orthogonal matrix  \n",
        "An orthogonal matrix is a **real square matrix** whose columns and rows are orthogonal vectors OR $M*M^{-1}=I$ where M is the orthogonal matrix.\n",
        "\n",
        "Here, the eigen vector matrix is not only orthogonal but also orthonormal because numpy normalises the obtained eigen vectors into unit vectors. \n",
        "\n",
        "For example:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMY7JE9DlspB",
        "outputId": "ea7cac30-aa4b-4d86-cc7a-2d76b659ce42"
      },
      "source": [
        "round(np.dot(eig_vec1,eig_vec1),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYzPNdgslHkG"
      },
      "source": [
        "**What are the properties of S?**  i.e., eigen vector matrix of a symmetric matrix\n",
        "-  eigen vectors are orthogonal to each other\n",
        "-  the inverse of eigen vector matrix is its transpose therefore eigen vector matrix of a symmetric matrix is an orthogonal matrix\n",
        "- if the eigen vectors are unit vectors then the eigen vector matrix is an orthonormal matrix. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj6o4kSVm4yP"
      },
      "source": [
        "Now let's answer the question, what is the form of matrix diagonalisation when the matrix is symmetric?\n",
        "\n",
        "$S^{-1}AS=\\Lambda$ this is when A is non symmetric    \n",
        "when A is symmetric the equation becomes $S^{T}AS=\\Lambda$\n",
        "\n",
        "This journey culminates with the spectral theorem  \n",
        "\n",
        "(3.3) **Spectral theorem**  \n",
        "Every symmetric matrix A can be factorised as $S\\Lambda S^{T}$ with $\\Lambda$ matrix holding real eigen values in its diagonal position and orthonormal eigen vectors sitting in the columns of S matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4EM-nzi3hjK"
      },
      "source": [
        "> Summary of Section 2 and 3\n",
        "- We have learnt that A can be factorised into $A=S \\Lambda S^{-1}$\n",
        "- This factorisation can be used to seamlessly compute $A^{n}$ by using the following formula $A^{n}=S \\Lambda^{n} S^{-1}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwEJIaWfsTMM"
      },
      "source": [
        "## Section 4: Positive definite & Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMLbsPbHtSkG"
      },
      "source": [
        "(4.1) **Definition** Positive definite matrix   \n",
        "A symmetric matrix whose eigen values are all positive\n",
        "\n",
        "**How to test for positive definitness?**\n",
        "The matrix A is positive definite if $x^{T}Ax>0$ for all nonzero vector X\n"
      ]
    }
  ]
}